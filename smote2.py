# -*- coding: utf-8 -*-
"""SMOTE.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nW3aZ__kwX5EufQvByHt8Vo2cTEHfm66
"""

import os
import numpy as np
from PIL import Image
from torch.utils import data
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms
# from tqdm import tqdm
import matplotlib.pyplot as plt
import json
import numpy as np
import torchvision
from torchvision import datasets, transforms, models
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import matplotlib.pyplot as plt
import time
import os
import copy
import json

from sklearn.model_selection import train_test_split
from sklearn.metrics import f1_score


BATCH_SIZE = 64
learning_rate = 0.001
num_epochs = 100


def findlabels(data_path):
    train_label = []
    f = open(data_path, 'r', encoding='utf-8')
    status = json.load(f)
    c = 0
    while c < 1500:
        eg = status['annotations'][c]['status']
        train_label.append(eg)
        c += 1
    return train_label


data_path = "/content/drive/My Drive/Colab Notebooks/amap_traffic_train_0712"
all_list = os.listdir(data_path)
all_label = findlabels("/content/drive/My Drive/Colab Notebooks/traffic.json")
train_list, test_list, train_label, test_label = train_test_split(all_list, all_label, test_size=0.20, random_state=3, stratify = all_label)
selected_frames = ["1.jpg", "2.jpg", "3.jpg", "4.jpg", "5.jpg"]
img_x = 224
img_y = 224
transform = transforms.Compose([transforms.Resize([img_x, img_y]),
                                transforms.ToTensor(),
                                transforms.Normalize([0.4451, 0.4687, 0.4713], [0.3244, 0.3277, 0.3358])])


  
class Dataset_3DCNN(data.Dataset):
    "Characterizes a dataset for PyTorch"

    def __init__(self, data_path, folders, labels, frames, transform=None):
        "Initialization"
        self.data_path = data_path
        self.labels = labels
        self.folders = folders
        self.transform = transform
        self.frames = frames

    def __len__(self):
        "Denotes the total number of samples"
        return len(self.folders)

    def read_images(self, path, selected_folder, use_transform):
        X = []
        for i in self.frames:
            m = os.path.join(path, selected_folder, '{}'.format(i))

            try:
                image = Image.open(m)
            except:

                continue

            if use_transform is not None:
                image = use_transform(image)

            X.append(image)
            if i == "5.jpg":
                X.pop(0)

        if len(X) < 4:
            X.append(image)
        elif len(X) > 4:
            X.pop(0)
        X = torch.stack(X, dim=0)
        return X

    def __getitem__(self, index):
        "Generates one sample of data"
        # Select sample
        folder = self.folders[index]

        # Load data
        X = self.read_images(self.data_path, folder, self.transform)  # (input) spatial images
        y = self.labels[index]  # (labels) LongTensor are for int64 instead of FloatTensor

        return X, y
traindatasets = Dataset_3DCNN(data_path, train_list, train_label, selected_frames, transform=transform)
testdatasets = Dataset_3DCNN(data_path, test_list, test_label, selected_frames, transform=transform)
train_data_loader = data.DataLoader(traindatasets, batch_size=1, shuffle=False, num_workers=4)
test_data_loader = data.DataLoader(testdatasets, batch_size=1, shuffle=False, num_workers=1)
all_data_loader = {"train": train_data_loader, "test": test_data_loader}
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# dl = iter(test_data_loader)

# from collections import Counter

# # for i in range(len(test_data_loader)):
# #   x= next(dl)[0]
# #   y = next(dl)[1]
# #   data.append((x.view(1,-1),y))
# x= []
# y =[]
# for _ in dl:
#   x.append(_[0].view(1,-1))
#   y.append(int(_[1]))



# print(Counter(y))

# a =[]
# for t in x:
#   a.append(t.numpy()[0])
# #print(a[0],a[1])
# from imblearn.over_sampling import SMOTE
# # 定义SMOTE模型，random_state相当于随机数种子的作用
# smo = SMOTE(random_state=42)
# smo = SMOTE(ratio={1: 219,2:219 },random_state=42)
# # 生成0和1比例为3比1的数据样本
# X_smo, y_smo = smo.fit_sample(a, y)

# from torch.utils import data
# class CRNNdatasets(data.Dataset):
#   def __init__(self,X_smo,y_smo):
#     self.X = X_smo
#     self.Y = y_smo
#   def __len__(self):
#     return len(self.X)
#   def __getitem__(self,index):
#     return X_smo[index].reshape(4,3,224,224),torch.LongTensor([y_smo[index]])
# testsmodatasets = CRNNdatasets(X_smo,y_smo)
# print(len(testsmodatasets))
# smote_test_dataloader = data.DataLoader(testsmodatasets, batch_size=BATCH_SIZE, shuffle=True, num_workers=1 )

dl = iter(train_data_loader)

from collections import Counter

# for i in range(len(test_data_loader)):
#   x= next(dl)[0]
#   y = next(dl)[1]
#   data.append((x.view(1,-1),y))
tx= []
ty =[]

for _ in dl:
  tx.append(_[0].view(1,-1))
  ty.append(int(_[1]))

print(Counter(ty))

temp =[]
for t in tx:
  temp.append(t.numpy()[0])
#print(a[0],a[1])
from imblearn.over_sampling import SMOTE
# 定义SMOTE模型，random_state相当于随机数种子的作用

smot = SMOTE(ratio={1:875,2:875},random_state=42)
# 生成0和1比例为3比1的数据样本
train_x_smo, train_y_smo = smot.fit_sample(temp,ty)